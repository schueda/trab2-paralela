\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{listings}
\floatname{algorithm}{Algoritmo}
\renewcommand{\algorithmicfor}{\textbf{Para}}
\renewcommand{\algorithmicwhile}{\textbf{Enquanto}}
\renewcommand{\algorithmicif}{\textbf{Se}}
\renewcommand{\algorithmicthen}{\textbf{então}}
\renewcommand{\algorithmicelse}{\textbf{Senão}}
\renewcommand{\algorithmicend}{\textbf{Fim}}
\renewcommand{\algorithmicdo}{\textbf{faça}}
\renewcommand{\tablename}{TABELA}
\renewcommand{\lstlistingname}{Código}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\lstdefinestyle{ieee}{
    language=C++,
    basicstyle=\ttfamily\footnotesize, 
    numbers=none,                      
    frame=single,                      
    breaklines=true,                   
    breakatwhitespace=true,
    columns=flexible,
    keepspaces=true,
    aboveskip=6pt,
    belowskip=6pt,
    captionpos=b,    
    backgroundcolor=\color{gray!5},    
    rulecolor=\color{gray!30},         
}

\begin{document}

\title{Trabalho 2 de programação paralela 2025/2}

\author{\IEEEauthorblockN{André Schueda Menezes (GRR20211785)}
\IEEEauthorblockA{\textit{Departamento de informática} \\
\textit{Universidade federal do Paraná}\\
Curitiba, Brasil \\
asm21@dinf.ufpr.br}
}

\maketitle

\begin{abstract}

Este relatório apresenta o estudo e implementação paralela em GPU do algoritmo para o Problema da Supersequência Mais Curta (SSP). O trabalho aborda estratégias
de paralelização utilizando OpenMP e analisa o desempenho do algoritmo em diferentes configurações de execução. A abordagem visa compreender a escalabilidade
e eficiência da solução paralela em comparação com a versão sequencial.

\end{abstract}

\begin{IEEEkeywords}
Problema da Supersequência Mais Curta, Computação Paralela, OpenMP, Otimização de Algoritmos, GPU
\end{IEEEkeywords}

\section{Introdução}

O Problema da Supersequência Mais Curta (Shortest Superstring Problem - SSP) é um problema clássico que pertence a classe de complexidade N
P-Difícil\cite{gallant1980finding}, tendo diversas aplicações como em compressão de dados\cite{storer1982data} e montagem de sequências 
genômicas\cite{gusfield1997algorithms}.

Este trabalho, desenvolvido para a disciplina de Programação Paralela (CI1316), consiste em analisar algoritmos para o problema e suas limitações, bem como 
desenvolver uma versão paralela utilizando \textbf{OpenMP}\cite{dagum1998openmp} e analisar os ganhos de desempenho. Para isso são utilizadas métricas como 
\textbf{\textit{speedup}} e \textbf{eficiência}.

As seções seguintes deste relatório serão organizadas da seguinte maneira:
\begin{itemize}
    \item Na seção \ref{sec:teorica} é feita uma análise teórica do algoritmo guloso dado, bem como suas limitações e otimizações.
    \item Na seção \ref{sec:paralela} é apresentada a abordagem para paralelização para o algoritmo.
    \item Na seção \ref{sec:metodologia} é apresentada a metodologia para os experimentos, assim como as especificações de Hardware, sistema operacional e demais especificações.
    \item Na seção \ref{sec:resultados} são apresentados e discutidos os resultados obtidos a partir das experimentações.
    \item Na seção \ref{sec:conclusao} são feitas as considerações finais sobre o trabalho.

\end{itemize}

\section{Análise teórica}
\label{sec:teorica}
Seja \(S = \{s_1, s_2, \dots, s_n\}\) o conjunto de sequências de entrada, onde nenhuma sequência é subsequência de outra. O problema da supersequência mais curta 
tem como objetivo encontrar uma sequência de tamanho mínimo que contenha todas as sequências de S como subsequência.

O algoritmo guloso para a construção da supersequência mais curta é definido a seguir:

\begin{algorithm}[H]
\caption{Supersequência Mais Curta Guloso(S)}
\label{alg:ssp_greedy}
\begin{algorithmic}[1]
\STATE $T \gets S$
\WHILE{$|T| > 1$}
    \STATE Escolha $a, b \in T$ com maior sobreposição
    \STATE Remova $a$ e $b$ de $T$
    \STATE Insira sobreposição de $a$ e $b$ em $T$
\ENDWHILE
\STATE \textbf{Retorne} única string em $T$
\end{algorithmic}
\end{algorithm}

A sobreposição de um par $a, b$ é definida como o comprimento máximo de um sufixo de $a$ que coincide com um prefixo de $b$.

Em outros termos, o algoritmo funciona juntando palavras de maior sobreposição, até que só reste uma palavra em $T$. A palavra restante é então retornada como 
resposta do algoritmo.

A complexidade do algoritmo \ref{alg:ssp_greedy} é definida pelo número de sequências da entrada $n$ multiplicado pela quantidade de passos necessários para achar o
par de maior sobreposição.

A implementaçõao inicial do trabalho recalcula todos os \textit{overlaps} a cada iteração, fazendo com que a quantidade de passos necessários para achar o par com 
maior sobreposição seja \(O(n^2 * m)\) onde $m$ é o tamanho máximo de caracteres em uma sequência da entrada. Fazendo com que a complexidade seja \(O(n^3 * m)\).

Partindo para uma abordagem um pouco menos ingênua, foi implementada uma otimização no algoritmo sequencial, de forma que a cada iteração apenas os \textit{overlaps}
da nova palavra formada sejam calculados e inseridos em uma fila de prioridade. Para isso, é necessário que o algoritmo calcule os \textit{overlaps} entre todas as 
palavras e insira na fila de prioridade ao início da execução. Dessa forma, a complexidade do algoritmo pôde ser reduzida para \(O(n^2 *lg(n)* m)\).

Como o Problema da Supersequência Mais Curta é NP-Difícil\cite{gallant1980finding}, não é conhecido algoritmo que compute a resposta exata para o problema em tempo polinomial. Dessa forma, o algoritmo guloso apresentado não garante a resposta exata do problema ao ser executado.

A rigor, Blum et al.\cite{blum1994linear} provaram que a resposta do algoritmo guloso para o SSP nunca tem tamanho maior que 4 vezes a resposta exata da instância, e é conjecturado que o algoritmo nunca tem resposta de tamanho maior que 2 vezes o tamanho da resposta exata \cite{tarhio1988greedy}.

Para exemplificar casos em que a resposta do algoritmo não é exata, uma entrada em que dois ou mais pares tem mesmo valor de sobreposição, a escolha de pares diferentes resulta em respostas diferentes. Este é o caso para a entrada \(S =  \{acc, ccb, ccc\}\). Caso na primeira iteração seja selecionado o par $acc, ccb$, a resposta final do algoritmo será $accbccc$. No entanto, caso na primeira iteração seja selecionado o par $acc, ccc$, tem-se como resposta a sequência $acccb$.

O exemplo anterior evidencia que a paralelização do algoritmo guloso pode ter diferentes respostas para diferentes execuções de uma mesma instância, uma vez que a ordem de escolha dos elementos com maior sobreposição pode estar sujeita a ordem de execução das \textit{threads}.

\section{Abordagem para paralelização}
\label{sec:paralela}

A implementação otimizada mencionada na seção anterior representa desafios quanto a sua paralezização. Isso porque, filas de prioridade normalmente são implementadas
utilizando uma estrutura de dados chamada de \textit{heap}. Ao adicionar ou remover elementos de uma \textit{heap}, vários elementos já presentes na \textit{heap}
precisam mudar de posição. Fazer isso de forma paralela não é viável, já que a inserção de novos elementos enquanto as mudanças de posição ainda estão ocorrendo
faria com que a \textit{heap} ficasse em um estado inconsistente. Por isso, para a paralelização em GPU, os \textit{overlaps} foram salvos em uma matriz.

O algoritmo paralelo buscou otimizar três pontos principais. Primeiramente, o cálculo inicial dos \textit{overlaps}, depois, a busca pelo \textit{overlap} máximo na
matriz, e por fim, no cálculo dos novos overlaps. Cada uma das três otimizações será melhor explicada a seguir. 

\subsection*{Cálculo inicial dos overlaps}

Para que os \textit{overlaps} pudessem ser calculados na GPU, foi necessário copiar todas as palavras da entrada para uma posição contígua de memória, como é
apresentado a seguir

\begin{lstlisting}[style=ieee, caption={Criação do buffer de palavras}]
const size_t n = words.size();
if (n == 0) return;

std::vector<size_t> lengths(n);
std::vector<size_t> offsets(n);
size_t total_chars = 0;

for (size_t i = 0; i < n; ++i) {
    lengths[i] = words[i].length();
    offsets[i] = total_chars;
    total_chars += lengths[i];
}
total_chars += n;

std::vector<char> all_words_buffer(total_chars);
char* all_words_ptr = all_words_buffer.data();

for (size_t i = 0; i < n; ++i) {
    offsets[i] += i;
    memcpy(all_words_ptr + offsets[i], words[i].c_str(), lengths[i] + 1);
}

int16_t* overlaps_ptr = overlaps.data();
size_t* lengths_ptr = lengths.data();
size_t* offsets_ptr = offsets.data();
\end{lstlisting}

O \textit{offload} para a GPU foi realizado da seguinte forma:
\begin{lstlisting}[style=ieee, caption={Offload do cálculo dos overlapas para GPU}]
#pragma omp target teams distribute parallel for \
    map(to: n, lengths_ptr[0:n], offsets_ptr[0:n], all_words_ptr[0:total_chars]) \
    map(from: overlaps_ptr[0:n*n]) \
    collapse(2)
for (size_t i = 0; i < n; i++) {
    for (size_t j = 0; j < n; j++) {
        if (i == j) {
            overlaps_ptr[IDX(i, j, n)] = -1;
        } else {
            const char* s1 = all_words_ptr + offsets_ptr[i];
            const char* s2 = all_words_ptr + offsets_ptr[j];
            size_t len1 = lengths_ptr[i];
            size_t len2 = lengths_ptr[j];

            overlaps_ptr[IDX(i, j, n)] = overlap(s1, len1, s2, len2);
        }
    }
}
\end{lstlisting}

Além disso, a função \textbf{\textit{overlap}} Foi marcada com a diretiva \texttt{\#pragma omp declare target} para que o cálculo do \textit{overlap} pudesse ser
realizado pela GPU, como é possível ver a seguir:
\begin{lstlisting}[style=ieee, caption={Função overlap com diretiva}]
#pragma omp declare target
int16_t overlap(const char* s1, size_t len1, const char* s2, size_t len2) {
    int16_t max_overlap = 0;
    for (int16_t k = 1; k <= (int16_t) (len1 < len2 ? len1 : len2); ++k) {
        if (strncmp(s1 + len1 - k, s2, k) == 0) {
            max_overlap = k;
        }
    }
    return max_overlap;
}
#pragma omp end declare target
\end{lstlisting}

\subsection*{Overlap máximo}
Para busca do overlap máximo foi definida a seguinte função:
\begin{lstlisting}[style=ieee, caption={Função que encontra o máximo na matriz}]
MaxOverlap max_overlap(const std::vector<int16_t>& overlaps, size_t n) {
    const int16_t* overlaps_ptr = overlaps.data();

    MaxOverlap max_result = {-1, 0, 0};

    #pragma omp target teams distribute parallel for \
        map(to: overlaps_ptr[0:n*n], n) \
        reduction(max_with_index : max_result)
    for (size_t i = 0; i < n * n; i++) {
        const int16_t current_val = overlaps_ptr[i];
        if (current_val > max_result.value) {
            max_result.value = current_val;
            max_result.i = i / n;
            max_result.j = i % n;
        }
    }

    return max_result;
}
\end{lstlisting}

Além disso foi necessário definir a struct \textbf{\textit{MaxOverlap}}, para que o \textit{reduction} do OpenMP retornasse também os índices do maior valor da matriz:
\begin{lstlisting}[style=ieee, caption={Struct MaxOverlap e declaração da redução}]
struct MaxOverlap {
    int16_t value;
    size_t i;
    size_t j;
};

#pragma omp declare reduction( \
    max_with_index : MaxOverlap : \
    omp_out = omp_in.value > omp_out.value ? omp_in : omp_out \
) initializer( \
    omp_priv = {-1, 0, 0} \
)
\end{lstlisting}

\subsection*{Cálculo de novos overlaps}

Para o cálculo de novos overlaps, é feita a criação do \textit{buffer} de palavras, de forma muito similar ao cálculo de todos os overlaps, e então o \textit{offload}
é realizado da seguinte maneira:
\begin{lstlisting}[style=ieee, caption={Struct MaxOverlap e declaração da redução}]
#pragma omp target teams distribute parallel for \
    map(to: n, st, lengths_ptr[0:n], offsets_ptr[0:n], all_words_ptr[0:total_chars]) \
    map(from: overlaps_ptr[0:n*n])
for (size_t k = 0; k < words.size(); k++) {
    if (st == k) {
        overlaps_ptr[IDX(st, k, ogn)] = -1;
        continue;
    }
    const char* s1 = all_words_ptr + offsets_ptr[st];
    const char* s2 = all_words_ptr + offsets_ptr[k];
    size_t len1 = lengths_ptr[st];
    size_t len2 = lengths_ptr[k];
    overlaps_ptr[IDX(st, k, ogn)] = overlap(s1, len1, s2, len2);
    overlaps_ptr[IDX(k, st, ogn)] = overlap(s2, len2, s1, len1);
}
\end{lstlisting}

\section{Metodologia Experimental}
\label{sec:metodologia}
Os experimentos foram realizados em uma máquina \textit{Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz}, com uma GPU \textit{NVDIA Corporation GM108M [GeForce MX110]}.
O sistema operacional utilizado foi o \textit{Ubuntu 24.04.3 LTS}, com kernel na versão \textit{6.14.0-35-generic}. 

Para executar os experimentos, a máquina foi inicializada no modo \textit{multi-user}, de forma que a interface gráfica não fosse carregada. Além disso foram 
desativadas as interfaces de rede e bluetooth para evitar interrupções. A execução do comando 
\begin{lstlisting}[language=sh, breaklines=true]
echo "1" | sudo tee /sys/devices/system/cpu/intel_pstate/no_turbo 
\end{lstlisting}
Foi realizada para que o \textit{Turbo Boost} fosse desativado.

Os programas foram compilados com \textit{g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0}. O programa sequencial utilizou as flags \texttt{-std=c++11 -Wall -O3 -fopenmp}.
Os programas com paralelização para GPU utilizaram as flags \texttt{-std=c++11 -Wall -O3 -fno-lto -fopenmp -fstack-protector}.

Para orquestrar a execução do algoritmo com diferentes diferentes entradas, foi desenvolvido um \textit{script} em \textit{Python}. O \textit{script} realizou 20 
execuções para cada entrada e cada programa. Foram realizados experimentos para entradas de tamanho 1000, 3000, 5000, 7000, e palavras de tamanho 10, 64, 128 e 256.
Os testes foram realizados sobre o algoritmo sequêncial utilizando fila de prioridade, o algoritmo com as três otimizações de GPU citadas na seção \ref{sec:paralela}
e um algoritmo em que a otimização para encontrar os novos overlaps não foi implementada.

Por fim, para validação dos resultados do algoritmo, foi desenvolvido outro \textit{script} em \textit{Python} que calcula o tamanho da \textit{string} resultante, 
e confere se todas as \textit{strings} da entrada estão presentes na \textit{string de saída}. Dessa forma, é possível validar o funcionamento do algoritmo mesmo que
sua saída possa variar de acordo com a ordem de execução das \textit{threads}.

\section{Resultados}
\label{sec:resultados}

Os resultados obtidos na experimentação são apresentados e discutidos a seguir. 

A tabela~\ref{tab:tempos} expõe os tempos obtidos a partir das execuções do algoritmo para as diferentes entradas.

A tabela~\ref{tab:speedup} apresenta os resultados dos cálculos do \textit{speedup}. O \textit{speedup} é a razão entre o tempo sequencial e o tempo paralelo.

Os resultados expõe a influência que o \textit{overhead} de comunicação entre GPU e processador têm sobre a performance dos programas. Isso fica evidente na queda 
do \textit{speedup} conforme a entrada aumenta de tamanho.

Além disso, a grande vantagem que o algoritmo paralelizado apresentou foi a paralelização da função \textit{overlap}. Para entradas com palavras de tamanho pequeno,
O \textit{overhead} acaba sobrepondo o ganho de performance. No entanto, para entradas com palavras maiores, a paralelização da função faz com que haja um ganho de
desempenho considerável, como é o caso da execução para palavras de tamanho 256.

Por fim, ao comparar a versão em que o cálculo dos novos overlaps não foi paralelizada, é possível assumir que a paralelização do trecho traz um ganho de desempenho
considerável, principalmente para entradas com palavras de tamanho maior.

\begin{table*}[htbp]
\centering
\caption{Tempos de execução para diferentes tamanhos de entrada e palavra}
\label{tab:tempos}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}
\toprule
entrada & \multicolumn{3}{c|}{10} & \multicolumn{3}{c|}{64} & \multicolumn{3}{c|}{128} & \multicolumn{3}{c|}{256} \\
\midrule
 & SEQ & GPU & GPUpart & SEQ & GPU & GPUpart & SEQ & GPU & GPUpart & SEQ & GPU & GPUpart \\
\midrule
\textbf{1000} & 1.13 ± 0.03 & 1.55 ± 0.11 & 0.92 ± 0.07 & 3.48 ± 0.03 & 1.75 ± 0.03 & 1.68 ± 0.02 & 6.62 ± 0.05 & 2.14 ± 0.08 & 2.62 ± 0.03 & 13.39 ± 0.04 & 2.86 ± 0.06 & 4.44 ± 0.02 \\
\textbf{3000} & 11.86 ± 0.10 & 11.01 ± 0.07 & 10.21 ± 0.04 & 33.22 ± 0.16 & 14.14 ± 0.07 & 17.47 ± 0.03 & 60.78 ± 0.08 & 17.87 ± 0.08 & 26.21 ± 0.07 & 121.30 ± 0.08 & 25.39 ± 0.10 & 44.04 ± 0.18 \\
\textbf{5000} & 33.07 ± 0.28 & 41.78 ± 0.09 & 41.24 ± 0.10 & 91.09 ± 0.22 & 50.84 ± 0.14 & 61.80 ± 0.08 & 167.50 ± 0.21 & 61.53 ± 0.12 & 86.68 ± 0.20 & 333.30 ± 0.41 & 82.78 ± 0.24 & 137.31 ± 0.37 \\
\textbf{7000} & 66.06 ± 0.69 & 107.29 ± 0.19 & 107.30 ± 0.19 & 178.29 ± 0.76 & 124.88 ± 0.11 & 148.31 ± 0.16 & 323.66 ± 0.48 & 146.48 ± 0.22 & 198.33 ± 0.36 & 651.02 ± 0.69 & 188.79 ± 0.42 & 295.98 ± 0.68 \\
\bottomrule
\end{tabular}%
}
\end{table*}

\begin{table*}[htbp]
\centering
\caption{Speedup para GPU e GPUpart para diferentes entradas e tamanhos de palavra}
\label{tab:speedup}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|c|c|}
\toprule
 & \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{64} & \multicolumn{2}{c|}{128} & \multicolumn{2}{c|}{256} \\
\midrule
entrada & GPU & GPUpart & GPU & GPUpart & GPU & GPUpart & GPU & GPUpart \\
\midrule
\textbf{1000} & 0.73 ± 0.06 & 1.23 ± 0.10 & 1.99 ± 0.04 & 2.07 ± 0.04 & 3.10 ± 0.12 & 2.52 ± 0.03 & 4.68 ± 0.10 & 3.02 ± 0.02 \\
\textbf{3000} & 1.08 ± 0.01 & 1.16 ± 0.01 & 2.35 ± 0.02 & 1.90 ± 0.01 & 3.40 ± 0.02 & 2.32 ± 0.01 & 4.78 ± 0.02 & 2.75 ± 0.01 \\
\textbf{5000} & 0.79 ± 0.01 & 0.80 ± 0.01 & 1.79 ± 0.01 & 1.47 ± 0.00 & 2.72 ± 0.01 & 1.93 ± 0.00 & 4.03 ± 0.01 & 2.43 ± 0.01 \\
\textbf{7000} & 0.62 ± 0.01 & 0.62 ± 0.01 & 1.43 ± 0.01 & 1.20 ± 0.01 & 2.21 ± 0.00 & 1.63 ± 0.00 & 3.45 ± 0.01 & 2.20 ± 0.01 \\
\bottomrule
\end{tabular}%
}
\end{table*}

\section{Conclusão}
\label{sec:conclusao}
O objetivo deste trabalho foi utilizar a GPU para paralelizar o algoritmo guloso para resolver o Problema da Supersequência Mais Curta e analisar os ganhos de 
desempenho. Além da implementação, o rigor metodológico teve grande relevância, criando um ambiente de experimentos controlado, com a desativação de otimizações 
de hardware e serviços do sistema, para garantir que os resultados fossem confiáveis e reprodutíveis.

Assim, o trabalho não se limitou à otimização do algoritmo, mas também contribuiu no desenvolvimento de habilidades fundamentais na pesquisa científica em computação,
como a formulação de hipóteses, condução de experimentos e interpretação crítica de resultados.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
